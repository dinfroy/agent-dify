"use strict";(self.webpackChunk_N_E=self.webpackChunk_N_E||[]).push([[806],{1268:(e,t,r)=>{r.r(t),r.d(t,{InferenceSession:()=>y,Tensor:()=>m,env:()=>l,registerBackend:()=>n});let i={},o=[],n=(e,t,r)=>{if(t&&"function"==typeof t.init&&"function"==typeof t.createSessionHandler){let n=i[e];if(void 0===n)i[e]={backend:t,priority:r};else if(n.priority>r)return;else if(n.priority===r&&n.backend!==t)throw Error(`cannot register backend "${e}" using priority ${r}`);if(r>=0){let t=o.indexOf(e);-1!==t&&o.splice(t,1);for(let t=0;t<o.length;t++)if(i[o[t]].priority<=r)return void o.splice(t,0,e);o.push(e)}return}throw TypeError("not a valid backend")},a=async e=>{let t=0===e.length?o:e,r=[];for(let e of t){let t=i[e];if(t){if(t.initialized)return t.backend;if(t.aborted)continue;let i=!!t.initPromise;try{return i||(t.initPromise=t.backend.init()),await t.initPromise,t.initialized=!0,t.backend}catch(o){i||r.push({name:e,err:o}),t.aborted=!0}finally{delete t.initPromise}}}throw Error(`no available backend found. ERR: ${r.map(e=>`[${e.name}] ${e.err}`).join(", ")}`)};class s{constructor(){this.wasm={},this.webgl={},this.logLevelInternal="warning"}set logLevel(e){if(void 0!==e){if("string"!=typeof e||-1===["verbose","info","warning","error","fatal"].indexOf(e))throw Error(`Unsupported logging level: ${e}`);this.logLevelInternal=e}}get logLevel(){return this.logLevelInternal}}let l=new s,h="undefined"!=typeof BigInt64Array&&"function"==typeof BigInt64Array.from,d="undefined"!=typeof BigUint64Array&&"function"==typeof BigUint64Array.from,u=new Map([["float32",Float32Array],["uint8",Uint8Array],["int8",Int8Array],["uint16",Uint16Array],["int16",Int16Array],["int32",Int32Array],["bool",Uint8Array],["float64",Float64Array],["uint32",Uint32Array]]),c=new Map([[Float32Array,"float32"],[Uint8Array,"uint8"],[Int8Array,"int8"],[Uint16Array,"uint16"],[Int16Array,"int16"],[Int32Array,"int32"],[Float64Array,"float64"],[Uint32Array,"uint32"]]);h&&(u.set("int64",BigInt64Array),c.set(BigInt64Array,"int64")),d&&(u.set("uint64",BigUint64Array),c.set(BigUint64Array,"uint64"));let f=e=>{let t=1;for(let r=0;r<e.length;r++){let i=e[r];if("number"!=typeof i||!Number.isSafeInteger(i))throw TypeError(`dims[${r}] must be an integer, got: ${i}`);if(i<0)throw RangeError(`dims[${r}] must be a non-negative integer, got: ${i}`);t*=i}return t};class p{constructor(e,t,r){let i,o,n;if("string"==typeof e)if(i=e,n=r,"string"===e){if(!Array.isArray(t))throw TypeError("A string tensor's data must be a string array.");o=t}else{let r=u.get(e);if(void 0===r)throw TypeError(`Unsupported tensor type: ${e}.`);if(Array.isArray(t))o=r.from(t);else if(t instanceof r)o=t;else throw TypeError(`A ${i} tensor's data must be type of ${r}`)}else if(n=t,Array.isArray(e)){if(0===e.length)throw TypeError("Tensor type cannot be inferred from an empty array.");let t=typeof e[0];if("string"===t)i="string",o=e;else if("boolean"===t)i="bool",o=Uint8Array.from(e);else throw TypeError(`Invalid element type of data array: ${t}.`)}else{let t=c.get(e.constructor);if(void 0===t)throw TypeError(`Unsupported type for tensor data: ${e.constructor}.`);i=t,o=e}if(void 0===n)n=[o.length];else if(!Array.isArray(n))throw TypeError("A tensor's dims must be a number array");let a=f(n);if(a!==o.length)throw Error(`Tensor's size(${a}) does not match data length(${o.length}).`);this.dims=n,this.type=i,this.data=o,this.size=a}static bufferToTensor(e,t){let r,i;if(void 0===e)throw Error("Image buffer must be defined");if(void 0===t.height||void 0===t.width)throw Error("Image height and width must be defined");let{height:o,width:n}=t,a=t.norm;r=void 0===a||void 0===a.mean?255:a.mean,i=void 0===a||void 0===a.bias?0:a.bias;let s=void 0!==t.bitmapFormat?t.bitmapFormat:"RGBA",l=void 0!==t.tensorFormat&&void 0!==t.tensorFormat?t.tensorFormat:"RGB",h=o*n,d=new Float32Array("RGBA"===l?4*h:3*h),u=4,c=0,f=1,m=2,g=3,y=0,w=h,v=2*h,b=-1;"RGB"===s&&(u=3,c=0,f=1,m=2,g=-1),"RGBA"===l?b=3*h:"RBG"===l?(y=0,v=h,w=2*h):"BGR"===l&&(v=0,w=h,y=2*h);for(let t=0;t<h;t++,c+=u,m+=u,f+=u,g+=u)d[y++]=(e[c]+i)/r,d[w++]=(e[f]+i)/r,d[v++]=(e[m]+i)/r,-1!==b&&-1!==g&&(d[b++]=(e[g]+i)/r);return"RGBA"===l?new p("float32",d,[1,4,o,n]):new p("float32",d,[1,3,o,n])}static async fromImage(e,t){let r,i="undefined"!=typeof HTMLImageElement&&e instanceof HTMLImageElement,o="undefined"!=typeof ImageData&&e instanceof ImageData,n="undefined"!=typeof ImageBitmap&&e instanceof ImageBitmap,a="undefined"!=typeof String&&(e instanceof String||"string"==typeof e),s={};if(i){let i=document.createElement("canvas"),o=i.getContext("2d");if(null!=o){let n=e.naturalHeight,a=e.naturalWidth;if(void 0!==t&&void 0!==t.resizedHeight&&void 0!==t.resizedWidth&&(n=t.resizedHeight,a=t.resizedWidth),void 0!==t){if(s=t,void 0!==t.tensorFormat)throw Error("Image input config format must be RGBA for HTMLImageElement");if(s.tensorFormat="RGBA",void 0!==t.height&&t.height!==n)throw Error("Image input config height doesn't match HTMLImageElement height");if(s.height=n,void 0!==t.width&&t.width!==a)throw Error("Image input config width doesn't match HTMLImageElement width");s.width=a}else s.tensorFormat="RGBA",s.height=n,s.width=a;i.width=a,i.height=n,o.drawImage(e,0,0,a,n),r=o.getImageData(0,0,a,n).data}else throw Error("Can not access image data")}else if(o){let i,o;if(void 0!==t&&void 0!==t.resizedWidth&&void 0!==t.resizedHeight?(i=t.resizedHeight,o=t.resizedWidth):(i=e.height,o=e.width),void 0!==t){if(s=t,void 0!==t.bitmapFormat&&"RGBA"!==t.bitmapFormat)throw Error("Image input config format must be RGBA for ImageData");s.bitmapFormat="RGBA"}else s.bitmapFormat="RGBA";if(s.height=i,s.width=o,void 0!==t){let t=document.createElement("canvas");t.width=o,t.height=i;let n=t.getContext("2d");if(null!=n)n.putImageData(e,0,0),r=n.getImageData(0,0,o,i).data;else throw Error("Can not access image data")}else r=e.data}else if(n){if(void 0===t)throw Error("Please provide image config with format for Imagebitmap");if(void 0!==t.bitmapFormat)throw Error("Image input config format must be defined for ImageBitmap");let i=document.createElement("canvas").getContext("2d");if(null!=i){let o=e.height,n=e.width;if(i.drawImage(e,0,0,n,o),r=i.getImageData(0,0,n,o).data,void 0!==t){if(void 0!==t.height&&t.height!==o)throw Error("Image input config height doesn't match ImageBitmap height");if(s.height=o,void 0!==t.width&&t.width!==n)throw Error("Image input config width doesn't match ImageBitmap width");s.width=n}else s.height=o,s.width=n;return p.bufferToTensor(r,s)}throw Error("Can not access image data")}else if(a)return new Promise((r,i)=>{let o=document.createElement("canvas"),n=o.getContext("2d");if(!e||!n)return i();let a=new Image;a.crossOrigin="Anonymous",a.src=e,a.onload=()=>{o.width=a.width,o.height=a.height,n.drawImage(a,0,0,o.width,o.height);let e=n.getImageData(0,0,o.width,o.height);if(void 0!==t){if(void 0!==t.height&&t.height!==o.height)throw Error("Image input config height doesn't match ImageBitmap height");if(s.height=o.height,void 0!==t.width&&t.width!==o.width)throw Error("Image input config width doesn't match ImageBitmap width");s.width=o.width}else s.height=o.height,s.width=o.width;r(p.bufferToTensor(e.data,s))}});else throw Error("Input data provided is not supported - aborted tensor creation");if(void 0!==r)return p.bufferToTensor(r,s);throw Error("Input data provided is not supported - aborted tensor creation")}toImageData(e){var t,r;let i,o=document.createElement("canvas").getContext("2d");if(null!=o){let n=this.dims[3],a=this.dims[2],s=this.dims[1],l=void 0!==e&&void 0!==e.format?e.format:"RGB",h=void 0!==e&&(null==(t=e.norm)?void 0:t.mean)!==void 0?e.norm.mean:255,d=void 0!==e&&(null==(r=e.norm)?void 0:r.bias)!==void 0?e.norm.bias:0,u=a*n;if(void 0!==e){if(void 0!==e.height&&e.height!==a)throw Error("Image output config height doesn't match tensor height");if(void 0!==e.width&&e.width!==n)throw Error("Image output config width doesn't match tensor width");if(void 0!==e.format&&4===s&&"RGBA"!==e.format||3===s&&"RGB"!==e.format&&"BGR"!==e.format)throw Error("Tensor format doesn't match input tensor dims")}let c=0,f=1,p=2,m=3,g=0,y=u,w=2*u,v=-1;"RGBA"===l?(g=0,y=u,w=2*u,v=3*u):"RGB"===l?(g=0,y=u,w=2*u):"RBG"===l&&(g=0,w=u,y=2*u),i=o.createImageData(n,a);for(let e=0;e<a*n;c+=4,f+=4,p+=4,m+=4,e++)i.data[c]=(this.data[g++]-d)*h,i.data[f]=(this.data[y++]-d)*h,i.data[p]=(this.data[w++]-d)*h,i.data[m]=-1===v?255:(this.data[v++]-d)*h}else throw Error("Can not access image data");return i}reshape(e){return new p(this.type,this.data,e)}}let m=p;class g{constructor(e){this.handler=e}async run(e,t,r){let i={},o={};if("object"!=typeof e||null===e||e instanceof m||Array.isArray(e))throw TypeError("'feeds' must be an object that use input names as keys and OnnxValue as corresponding values.");let n=!0;if("object"==typeof t){if(null===t)throw TypeError("Unexpected argument[1]: cannot be null.");if(t instanceof m)throw TypeError("'fetches' cannot be a Tensor");if(Array.isArray(t)){if(0===t.length)throw TypeError("'fetches' cannot be an empty array.");for(let e of(n=!1,t)){if("string"!=typeof e)throw TypeError("'fetches' must be a string array or an object.");if(-1===this.outputNames.indexOf(e))throw RangeError(`'fetches' contains invalid output name: ${e}.`);i[e]=null}if("object"==typeof r&&null!==r)o=r;else if(void 0!==r)throw TypeError("'options' must be an object.")}else{let e=!1,a=Object.getOwnPropertyNames(t);for(let r of this.outputNames)if(-1!==a.indexOf(r)){let o=t[r];(null===o||o instanceof m)&&(e=!0,n=!1,i[r]=o)}if(e){if("object"==typeof r&&null!==r)o=r;else if(void 0!==r)throw TypeError("'options' must be an object.")}else o=t}}else if(void 0!==t)throw TypeError("Unexpected argument[1]: must be 'fetches' or 'options'.");for(let t of this.inputNames)if(void 0===e[t])throw Error(`input '${t}' is missing in 'feeds'.`);if(n)for(let e of this.outputNames)i[e]=null;let a=await this.handler.run(e,i,o),s={};for(let e in a)Object.hasOwnProperty.call(a,e)&&(s[e]=new m(a[e].type,a[e].data,a[e].dims));return s}static async create(e,t,r,i){let o,n={};if("string"==typeof e){if(o=e,"object"==typeof t&&null!==t)n=t;else if(void 0!==t)throw TypeError("'options' must be an object.")}else if(e instanceof Uint8Array){if(o=e,"object"==typeof t&&null!==t)n=t;else if(void 0!==t)throw TypeError("'options' must be an object.")}else if(e instanceof ArrayBuffer||"undefined"!=typeof SharedArrayBuffer&&e instanceof SharedArrayBuffer){let a=0,s=e.byteLength;if("object"==typeof t&&null!==t)n=t;else if("number"==typeof t){if(!Number.isSafeInteger(a=t))throw RangeError("'byteOffset' must be an integer.");if(a<0||a>=e.byteLength)throw RangeError(`'byteOffset' is out of range [0, ${e.byteLength}).`);if(s=e.byteLength-a,"number"==typeof r){if(!Number.isSafeInteger(s=r))throw RangeError("'byteLength' must be an integer.");if(s<=0||a+s>e.byteLength)throw RangeError(`'byteLength' is out of range (0, ${e.byteLength-a}].`);if("object"==typeof i&&null!==i)n=i;else if(void 0!==i)throw TypeError("'options' must be an object.")}else if(void 0!==r)throw TypeError("'byteLength' must be a number.")}else if(void 0!==t)throw TypeError("'options' must be an object.");o=new Uint8Array(e,a,s)}else throw TypeError("Unexpected argument[0]: must be 'path' or 'buffer'.");let s=(n.executionProviders||[]).map(e=>"string"==typeof e?e:e.name),l=await a(s);return new g(await l.createSessionHandler(o,n))}startProfiling(){this.handler.startProfiling()}endProfiling(){this.handler.endProfiling()}get inputNames(){return this.handler.inputNames}get outputNames(){return this.handler.outputNames}}let y=g},1500:(e,t,r)=>{r.d(t,{u4:()=>a});function i(){return"undefined"!=typeof window}function o(){return(i()?window.vam:function(){return"production"}())||"production"}function n(){return"production"===o()}function a(e,t,r){var a,s;if(!i()){let e="[Vercel Web Analytics] Please import `track` from `@vercel/analytics/server` when using this function in a server environment";if(n())console.warn(e);else throw Error(e);return}if(!t){null==(a=window.va)||a.call(window,"event",{name:e,options:r});return}try{let i=function(e,t){if(!e)return;let r=e,i=[];for(let[o,n]of Object.entries(e))"object"==typeof n&&null!==n&&(t.strip?r=function(e,{[e]:t,...r}){return r}(o,r):i.push(o));if(i.length>0&&!t.strip)throw Error(`The following properties are not valid: ${i.join(", ")}. Only strings, numbers, booleans, and null are allowed.`);return r}(t,{strip:n()});null==(s=window.va)||s.call(window,"event",{name:e,data:i,options:r})}catch(e){e instanceof Error&&"development"===o()&&console.error(e)}}},1676:function(e,t,r){var i=this&&this.__createBinding||(Object.create?function(e,t,r,i){void 0===i&&(i=r);var o=Object.getOwnPropertyDescriptor(t,r);(!o||("get"in o?!t.__esModule:o.writable||o.configurable))&&(o={enumerable:!0,get:function(){return t[r]}}),Object.defineProperty(e,i,o)}:function(e,t,r,i){void 0===i&&(i=r),e[i]=t[r]}),o=this&&this.__setModuleDefault||(Object.create?function(e,t){Object.defineProperty(e,"default",{enumerable:!0,value:t})}:function(e,t){e.default=t}),n=this&&this.__importStar||function(e){if(e&&e.__esModule)return e;var t={};if(null!=e)for(var r in e)"default"!==r&&Object.prototype.hasOwnProperty.call(e,r)&&i(t,e,r);return o(t,e),t};Object.defineProperty(t,"__esModule",{value:!0}),t.AudioNodeVAD=t.MicVAD=t.getDefaultRealTimeVADOptions=t.ort=t.DEFAULT_MODEL=void 0;let a=n(r(6960)),s=r(6115),l=r(6472),h=r(3337),d=r(3544),u=r(4117),c=r(7279);t.DEFAULT_MODEL="legacy",t.ort=a,t.getDefaultRealTimeVADOptions=e=>({..."v5"===e?l.defaultV5FrameProcessorOptions:l.defaultLegacyFrameProcessorOptions,onFrameProcessed:e=>{},onVADMisfire:()=>{h.log.debug("VAD misfire")},onSpeechStart:()=>{h.log.debug("Detected speech start")},onSpeechEnd:()=>{h.log.debug("Detected speech end")},baseAssetPath:"https://cdn.jsdelivr.net/npm/@ricky0123/vad-web@0.0.22/dist/",onnxWASMBasePath:"https://cdn.jsdelivr.net/npm/onnxruntime-web@1.14.0/dist/",stream:void 0,ortConfig:void 0,model:t.DEFAULT_MODEL,workletOptions:{}});class f{static async new(e={}){let r,i={...(0,t.getDefaultRealTimeVADOptions)(e.model??t.DEFAULT_MODEL),...e};(0,l.validateOptions)(i),r=void 0===i.stream?await navigator.mediaDevices.getUserMedia({audio:{...i.additionalAudioConstraints,channelCount:1,echoCancellation:!0,autoGainControl:!0,noiseSuppression:!0}}):i.stream;let o=new AudioContext,n=new MediaStreamAudioSourceNode(o,{mediaStream:r}),a=await p.new(o,i);return a.receive(n),new f(i,o,r,a,n)}constructor(e,t,r,i,o,n=!1){this.options=e,this.audioContext=t,this.stream=r,this.audioNodeVAD=i,this.sourceNode=o,this.listening=n,this.pause=()=>{this.audioNodeVAD.pause(),this.listening=!1},this.start=()=>{this.audioNodeVAD.start(),this.listening=!0},this.destroy=()=>{this.listening&&this.pause(),void 0===this.options.stream&&this.stream.getTracks().forEach(e=>e.stop()),this.sourceNode.disconnect(),this.audioNodeVAD.destroy(),this.audioContext.close()}}}t.MicVAD=f;class p{static async new(e,r={}){let i,o={...(0,t.getDefaultRealTimeVADOptions)(r.model??t.DEFAULT_MODEL),...r};(0,l.validateOptions)(o),t.ort.env.wasm.wasmPaths=o.onnxWASMBasePath,void 0!==o.ortConfig&&o.ortConfig(t.ort);let n="v5"===o.model?"silero_vad_v5.onnx":"silero_vad_legacy.onnx",a=o.baseAssetPath+n,h="v5"===o.model?u.SileroV5.new:u.SileroLegacy.new;try{i=await h(t.ort,()=>(0,s.defaultModelFetcher)(a))}catch(e){throw console.error(`Encountered an error while loading model file ${a}`),e}let d=new l.FrameProcessor(i.process,i.reset_state,{frameSamples:o.frameSamples,positiveSpeechThreshold:o.positiveSpeechThreshold,negativeSpeechThreshold:o.negativeSpeechThreshold,redemptionFrames:o.redemptionFrames,preSpeechPadFrames:o.preSpeechPadFrames,minSpeechFrames:o.minSpeechFrames,submitUserSpeechOnPause:o.submitUserSpeechOnPause}),c=new p(e,o,d);return await c.setupAudioNode(),c}constructor(e,t,r){this.ctx=e,this.options=t,this.bufferIndex=0,this.pause=()=>{let e=this.frameProcessor.pause();this.handleFrameProcessorEvent(e)},this.start=()=>{this.frameProcessor.resume()},this.receive=e=>{e.connect(this.audioNode)},this.processFrame=async e=>{let t=await this.frameProcessor.process(e);this.handleFrameProcessorEvent(t)},this.handleFrameProcessorEvent=e=>{switch(void 0!==e.probs&&this.options.onFrameProcessed(e.probs,e.frame),e.msg){case d.Message.SpeechStart:this.options.onSpeechStart();break;case d.Message.VADMisfire:this.options.onVADMisfire();break;case d.Message.SpeechEnd:this.options.onSpeechEnd(e.audio)}},this.destroy=()=>{this.audioNode instanceof AudioWorkletNode&&this.audioNode.port.postMessage({message:d.Message.SpeechStop}),this.audioNode.disconnect(),this.gainNode?.disconnect()},this.frameProcessor=r}async setupAudioNode(){if("audioWorklet"in this.ctx&&"function"==typeof AudioWorkletNode)try{let e=this.options.baseAssetPath+"vad.worklet.bundle.min.js";await this.ctx.audioWorklet.addModule(e);let t=this.options.workletOptions??{};t.processorOptions={...t.processorOptions??{},frameSamples:this.options.frameSamples},this.audioNode=new AudioWorkletNode(this.ctx,"vad-helper-worklet",t),this.audioNode.port.onmessage=async e=>{if(e.data?.message===d.Message.AudioFrame){let t=e.data.data;t instanceof ArrayBuffer||(t=new ArrayBuffer(e.data.data.byteLength),new Uint8Array(t).set(new Uint8Array(e.data.data)));let r=new Float32Array(t);await this.processFrame(r)}};return}catch(e){console.log("AudioWorklet setup failed, falling back to ScriptProcessor",e)}this.resampler=new c.Resampler({nativeSampleRate:this.ctx.sampleRate,targetSampleRate:16e3,targetFrameSize:this.options.frameSamples??480}),this.audioNode=this.ctx.createScriptProcessor(4096,1,1),this.gainNode=this.ctx.createGain(),this.gainNode.gain.value=0;let e=!1;this.audioNode.onaudioprocess=async t=>{if(!e){e=!0;try{let e=t.inputBuffer.getChannelData(0);if(t.outputBuffer.getChannelData(0).fill(0),this.resampler)for(let t of this.resampler.process(e))await this.processFrame(t)}catch(e){console.error("Error processing audio:",e)}finally{e=!1}}},this.audioNode.connect(this.gainNode),this.gainNode.connect(this.ctx.destination)}}t.AudioNodeVAD=p},2596:(e,t,r)=>{r.d(t,{A:()=>i});let i=function(){for(var e,t,r=0,i="",o=arguments.length;r<o;r++)(e=arguments[r])&&(t=function e(t){var r,i,o="";if("string"==typeof t||"number"==typeof t)o+=t;else if("object"==typeof t)if(Array.isArray(t)){var n=t.length;for(r=0;r<n;r++)t[r]&&(i=e(t[r]))&&(o&&(o+=" "),o+=i)}else for(i in t)t[i]&&(o&&(o+=" "),o+=i);return o}(e))&&(i&&(i+=" "),i+=t);return i}},3056:function(e,t,r){var i=this&&this.__createBinding||(Object.create?function(e,t,r,i){void 0===i&&(i=r);var o=Object.getOwnPropertyDescriptor(t,r);(!o||("get"in o?!t.__esModule:o.writable||o.configurable))&&(o={enumerable:!0,get:function(){return t[r]}}),Object.defineProperty(e,i,o)}:function(e,t,r,i){void 0===i&&(i=r),e[i]=t[r]}),o=this&&this.__setModuleDefault||(Object.create?function(e,t){Object.defineProperty(e,"default",{enumerable:!0,value:t})}:function(e,t){e.default=t}),n=this&&this.__importStar||function(e){if(e&&e.__esModule)return e;var t={};if(null!=e)for(var r in e)"default"!==r&&Object.prototype.hasOwnProperty.call(e,r)&&i(t,e,r);return o(t,e),t};Object.defineProperty(t,"__esModule",{value:!0}),t.NonRealTimeVAD=t.Message=t.FrameProcessor=t.getDefaultRealTimeVADOptions=t.MicVAD=t.DEFAULT_MODEL=t.AudioNodeVAD=t.utils=t.defaultNonRealTimeVADOptions=void 0;let a=n(r(6960)),s=r(5612),l=r(6115),h=r(6472);Object.defineProperty(t,"FrameProcessor",{enumerable:!0,get:function(){return h.FrameProcessor}});let d=r(3544);Object.defineProperty(t,"Message",{enumerable:!0,get:function(){return d.Message}});let u=r(7674),c=r(4589);t.defaultNonRealTimeVADOptions={modelURL:s.baseAssetPath+"silero_vad_legacy.onnx",modelFetcher:l.defaultModelFetcher};class f extends u.PlatformAgnosticNonRealTimeVAD{static async new(e={}){let{modelURL:r,modelFetcher:i}={...t.defaultNonRealTimeVADOptions,...e};return await this._new(()=>i(r),a,e)}}t.NonRealTimeVAD=f,t.utils={audioFileToArray:c.audioFileToArray,minFramesForTargetMS:c.minFramesForTargetMS,arrayBufferToBase64:c.arrayBufferToBase64,encodeWAV:c.encodeWAV};var p=r(1676);Object.defineProperty(t,"AudioNodeVAD",{enumerable:!0,get:function(){return p.AudioNodeVAD}}),Object.defineProperty(t,"DEFAULT_MODEL",{enumerable:!0,get:function(){return p.DEFAULT_MODEL}}),Object.defineProperty(t,"MicVAD",{enumerable:!0,get:function(){return p.MicVAD}}),Object.defineProperty(t,"getDefaultRealTimeVADOptions",{enumerable:!0,get:function(){return p.getDefaultRealTimeVADOptions}})},3139:function(e,t,r){var i=this&&this.__createBinding||(Object.create?function(e,t,r,i){void 0===i&&(i=r);var o=Object.getOwnPropertyDescriptor(t,r);(!o||("get"in o?!t.__esModule:o.writable||o.configurable))&&(o={enumerable:!0,get:function(){return t[r]}}),Object.defineProperty(e,i,o)}:function(e,t,r,i){void 0===i&&(i=r),e[i]=t[r]}),o=this&&this.__setModuleDefault||(Object.create?function(e,t){Object.defineProperty(e,"default",{enumerable:!0,value:t})}:function(e,t){e.default=t}),n=this&&this.__importStar||function(e){if(e&&e.__esModule)return e;var t={};if(null!=e)for(var r in e)"default"!==r&&Object.prototype.hasOwnProperty.call(e,r)&&i(t,e,r);return o(t,e),t};Object.defineProperty(t,"__esModule",{value:!0}),t.useMicVAD=t.getDefaultReactRealTimeVADOptions=t.utils=void 0;let a=r(3056),s=n(r(2115));var l=r(3056);Object.defineProperty(t,"utils",{enumerable:!0,get:function(){return l.utils}});let h={startOnLoad:!0,userSpeakingThreshold:.6};t.getDefaultReactRealTimeVADOptions=e=>({...(0,a.getDefaultRealTimeVADOptions)(e),...h});let d=Object.keys(h),u=Object.keys((0,a.getDefaultRealTimeVADOptions)("v5")),c=(e,t)=>e.reduce((e,r)=>(e[r]=t[r],e),{});function f(e){let t=s.default.useRef(e);return p(()=>{t.current=e}),s.default.useCallback((...e)=>t.current.apply(void 0,e),[])}t.useMicVAD=function(e){let[r,i]=function(e){let r=e.model??a.DEFAULT_MODEL;return[c(d,e={...(0,t.getDefaultReactRealTimeVADOptions)(r),...e}),c(u,e)]}(e),[o,n]=(0,s.useReducer)((e,t)=>t>r.userSpeakingThreshold,!1),[l,h]=(0,s.useState)(!0),[p,m]=(0,s.useState)(!1),[g,y]=(0,s.useState)(!1),[w,v]=(0,s.useState)(null),b=f(i.onFrameProcessed);i.onFrameProcessed=f((e,t)=>{n(e.isSpeech),b(e,t)});let{onSpeechEnd:A,onSpeechStart:S,onVADMisfire:O}=i,E=f(A),F=f(S),T=f(O);i.onSpeechEnd=E,i.onSpeechStart=F,i.onVADMisfire=T,(0,s.useEffect)(()=>{let e,t=!1;return(async()=>{try{if(e=await a.MicVAD.new(i),t)return void e.destroy()}catch(e){h(!1),e instanceof Error?m(e.message):m(String(e));return}v(e),h(!1),r.startOnLoad&&(e?.start(),y(!0))})().catch(e=>{console.log("Well that didn't work")}),function(){e?.destroy(),t=!0,l||p||y(!1)}},[]);let P=()=>{l||p||(w?.pause(),y(!1))},_=()=>{l||p||(w?.start(),y(!0))};return{listening:g,errored:p,loading:l,userSpeaking:o,pause:P,start:_,toggle:()=>{g?P():_()}}};let p="undefined"!=typeof window&&void 0!==window.document&&void 0!==window.document.createElement?s.default.useLayoutEffect:s.default.useEffect},3337:(e,t)=>{Object.defineProperty(t,"__esModule",{value:!0}),t.log=t.LOG_PREFIX=void 0,t.LOG_PREFIX="[VAD]";let r=["error","debug","warn"].reduce((e,r)=>(e[r]=(...e)=>{console[r](t.LOG_PREFIX,...e)},e),{});t.log=r},3544:(e,t)=>{var r;Object.defineProperty(t,"__esModule",{value:!0}),t.Message=void 0,function(e){e.AudioFrame="AUDIO_FRAME",e.SpeechStart="SPEECH_START",e.VADMisfire="VAD_MISFIRE",e.SpeechEnd="SPEECH_END",e.SpeechStop="SPEECH_STOP"}(r||(t.Message=r={}))},4117:function(e,t,r){var i=this&&this.__createBinding||(Object.create?function(e,t,r,i){void 0===i&&(i=r);var o=Object.getOwnPropertyDescriptor(t,r);(!o||("get"in o?!t.__esModule:o.writable||o.configurable))&&(o={enumerable:!0,get:function(){return t[r]}}),Object.defineProperty(e,i,o)}:function(e,t,r,i){void 0===i&&(i=r),e[i]=t[r]}),o=this&&this.__exportStar||function(e,t){for(var r in e)"default"===r||Object.prototype.hasOwnProperty.call(t,r)||i(t,e,r)};Object.defineProperty(t,"__esModule",{value:!0}),t.SileroV5=t.SileroLegacy=void 0,o(r(9766),t);var n=r(7476);Object.defineProperty(t,"SileroLegacy",{enumerable:!0,get:function(){return n.SileroLegacy}});var a=r(5326);Object.defineProperty(t,"SileroV5",{enumerable:!0,get:function(){return a.SileroV5}})},4589:(e,t)=>{function r(e,t,r){for(var i=0;i<r.length;i++)e.setUint8(t+i,r.charCodeAt(i))}Object.defineProperty(t,"__esModule",{value:!0}),t.audioFileToArray=t.encodeWAV=t.arrayBufferToBase64=t.minFramesForTargetMS=void 0,t.minFramesForTargetMS=function(e,t,r=16e3){return Math.ceil(e*r/1e3/t)},t.arrayBufferToBase64=function(e){let t=new Uint8Array(e),r=t.byteLength,i=Array(r);for(var o=0;o<r;o++){let e=t[o];if(void 0===e)break;i[o]=String.fromCharCode(e)}return btoa(i.join(""))},t.encodeWAV=function(e,t=3,i=16e3,o=1,n=32){var a=n/8,s=o*a,l=new ArrayBuffer(44+e.length*a),h=new DataView(l);return r(h,0,"RIFF"),h.setUint32(4,36+e.length*a,!0),r(h,8,"WAVE"),r(h,12,"fmt "),h.setUint32(16,16,!0),h.setUint16(20,t,!0),h.setUint16(22,o,!0),h.setUint32(24,i,!0),h.setUint32(28,i*s,!0),h.setUint16(32,s,!0),h.setUint16(34,n,!0),r(h,36,"data"),h.setUint32(40,e.length*a,!0),1===t?function(e,t,r){for(var i=0;i<r.length;i++,t+=2){var o=Math.max(-1,Math.min(1,r[i]));e.setInt16(t,o<0?32768*o:32767*o,!0)}}(h,44,e):function(e,t,r){for(var i=0;i<r.length;i++,t+=4)e.setFloat32(t,r[i],!0)}(h,44,e),l},t.audioFileToArray=async function(e){let t=new OfflineAudioContext(1,1,44100),r=new FileReader,i=null;if(await new Promise(o=>{r.addEventListener("loadend",e=>{let n=r.result;t.decodeAudioData(n,e=>{i=e,t.startRendering().then(e=>{console.log("Rendering completed successfully"),o()}).catch(e=>{console.error(`Rendering failed: ${e}`)})},e=>{console.log(`Error with decoding audio data: ${e}`)})}),r.readAsArrayBuffer(e)}),null===i)throw Error("some shit");let o=i,n=new Float32Array(o.length);for(let e=0;e<o.length;e++)for(let t=0;t<o.numberOfChannels;t++)n[e]+=o.getChannelData(t)[e];return{audio:n,sampleRate:o.sampleRate}}},5326:(e,t,r)=>{Object.defineProperty(t,"__esModule",{value:!0}),t.SileroV5=void 0;let i=r(3337);function o(e){let t=Array(256).fill(0);return new e.Tensor("float32",t,[2,1,128])}class n{constructor(e,t,r,i){this._session=e,this._state=t,this._sr=r,this.ortInstance=i,this.reset_state=()=>{this._state=o(this.ortInstance)},this.process=async e=>{let t={input:new this.ortInstance.Tensor("float32",e,[1,e.length]),state:this._state,sr:this._sr},r=await this._session.run(t);this._state=r.stateN;let[i]=r.output?.data;return{notSpeech:1-i,isSpeech:i}}}}t.SileroV5=n,n.new=async(e,t)=>{i.log.debug("Loading VAD...");let r=await t(),a=await e.InferenceSession.create(r),s=new e.Tensor("int64",[16000n]),l=o(e);return i.log.debug("...finished loading VAD"),new n(a,l,s,e)}},5612:(e,t)=>{Object.defineProperty(t,"__esModule",{value:!0}),t.baseAssetPath=void 0;let r="undefined"!=typeof window&&void 0!==window.document?window.document.currentScript:null,i="/";r&&(i=r.src.replace(/#.*$/,"").replace(/\?.*$/,"").replace(/\/[^\/]+$/,"/")),t.baseAssetPath=i},6115:(e,t)=>{Object.defineProperty(t,"__esModule",{value:!0}),t.defaultModelFetcher=void 0,t.defaultModelFetcher=e=>fetch(e).then(e=>e.arrayBuffer())},6472:(e,t,r)=>{Object.defineProperty(t,"__esModule",{value:!0}),t.FrameProcessor=t.validateOptions=t.defaultV5FrameProcessorOptions=t.defaultLegacyFrameProcessorOptions=void 0;let i=r(3337),o=r(3544),n=[512,1024,1536];t.defaultLegacyFrameProcessorOptions={positiveSpeechThreshold:.5,negativeSpeechThreshold:.35,preSpeechPadFrames:1,redemptionFrames:8,frameSamples:1536,minSpeechFrames:3,submitUserSpeechOnPause:!1},t.defaultV5FrameProcessorOptions={positiveSpeechThreshold:.5,negativeSpeechThreshold:.35,preSpeechPadFrames:3,redemptionFrames:24,frameSamples:512,minSpeechFrames:9,submitUserSpeechOnPause:!1},t.validateOptions=function(e){n.includes(e.frameSamples)||i.log.warn("You are using an unusual frame size"),(e.positiveSpeechThreshold<0||e.positiveSpeechThreshold>1)&&i.log.error("positiveSpeechThreshold should be a number between 0 and 1"),(e.negativeSpeechThreshold<0||e.negativeSpeechThreshold>e.positiveSpeechThreshold)&&i.log.error("negativeSpeechThreshold should be between 0 and positiveSpeechThreshold"),e.preSpeechPadFrames<0&&i.log.error("preSpeechPadFrames should be positive"),e.redemptionFrames<0&&i.log.error("redemptionFrames should be positive")};let a=e=>{let t=e.reduce((e,t)=>(e.push(e.at(-1)+t.length),e),[0]),r=new Float32Array(t.at(-1));return e.forEach((e,i)=>{let o=t[i];r.set(e,o)}),r};class s{constructor(e,t,r){this.modelProcessFunc=e,this.modelResetFunc=t,this.options=r,this.speaking=!1,this.redemptionCounter=0,this.active=!1,this.reset=()=>{this.speaking=!1,this.audioBuffer=[],this.modelResetFunc(),this.redemptionCounter=0},this.pause=()=>(this.active=!1,this.options.submitUserSpeechOnPause)?this.endSegment():(this.reset(),{}),this.resume=()=>{this.active=!0},this.endSegment=()=>{let e=this.audioBuffer;this.audioBuffer=[];let t=this.speaking;this.reset();let r=e.reduce((e,t)=>e+ +t.isSpeech,0);if(t)if(!(r>=this.options.minSpeechFrames))return{msg:o.Message.VADMisfire};else{let t=a(e.map(e=>e.frame));return{msg:o.Message.SpeechEnd,audio:t}}return{}},this.process=async e=>{if(!this.active)return{};let t=await this.modelProcessFunc(e);if(this.audioBuffer.push({frame:e,isSpeech:t.isSpeech>=this.options.positiveSpeechThreshold}),t.isSpeech>=this.options.positiveSpeechThreshold&&this.redemptionCounter&&(this.redemptionCounter=0),t.isSpeech>=this.options.positiveSpeechThreshold&&!this.speaking)return this.speaking=!0,{probs:t,msg:o.Message.SpeechStart,frame:e};if(t.isSpeech<this.options.negativeSpeechThreshold&&this.speaking&&++this.redemptionCounter>=this.options.redemptionFrames){this.redemptionCounter=0,this.speaking=!1;let r=this.audioBuffer;if(this.audioBuffer=[],!(r.reduce((e,t)=>e+ +t.isSpeech,0)>=this.options.minSpeechFrames))return{probs:t,msg:o.Message.VADMisfire,frame:e};{let i=a(r.map(e=>e.frame));return{probs:t,msg:o.Message.SpeechEnd,audio:i,frame:e}}}if(!this.speaking)for(;this.audioBuffer.length>this.options.preSpeechPadFrames;)this.audioBuffer.shift();return{probs:t,frame:e}},this.audioBuffer=[],this.reset()}}t.FrameProcessor=s},7279:(e,t,r)=>{Object.defineProperty(t,"__esModule",{value:!0}),t.Resampler=void 0;let i=r(3337);class o{constructor(e){this.options=e,this.process=e=>{let t=[];for(let r of e)for(this.inputBuffer.push(r);this.hasEnoughDataForFrame();){let e=this.generateOutputFrame();t.push(e)}return t},this.stream=async function*(e){for(let t of e)for(this.inputBuffer.push(t);this.hasEnoughDataForFrame();){let e=this.generateOutputFrame();yield e}},e.nativeSampleRate<16e3&&i.log.error("nativeSampleRate is too low. Should have 16000 = targetSampleRate <= nativeSampleRate"),this.inputBuffer=[]}hasEnoughDataForFrame(){return this.inputBuffer.length*this.options.targetSampleRate/this.options.nativeSampleRate>=this.options.targetFrameSize}generateOutputFrame(){let e=new Float32Array(this.options.targetFrameSize),t=0,r=0;for(;t<this.options.targetFrameSize;){let i=0,o=0;for(;r<Math.min(this.inputBuffer.length,(t+1)*this.options.nativeSampleRate/this.options.targetSampleRate);){let e=this.inputBuffer[r];void 0!==e&&(i+=e,o++),r++}e[t]=i/o,t++}return this.inputBuffer=this.inputBuffer.slice(r),e}}t.Resampler=o},7476:(e,t,r)=>{Object.defineProperty(t,"__esModule",{value:!0}),t.SileroLegacy=void 0;let i=r(3337);class o{constructor(e,t,r,i,o){this.ortInstance=e,this._session=t,this._h=r,this._c=i,this._sr=o,this.reset_state=()=>{let e=Array(128).fill(0);this._h=new this.ortInstance.Tensor("float32",e,[2,1,64]),this._c=new this.ortInstance.Tensor("float32",e,[2,1,64])},this.process=async e=>{let t={input:new this.ortInstance.Tensor("float32",e,[1,e.length]),h:this._h,c:this._c,sr:this._sr},r=await this._session.run(t);this._h=r.hn,this._c=r.cn;let[i]=r.output?.data;return{notSpeech:1-i,isSpeech:i}}}}t.SileroLegacy=o,o.new=async(e,t)=>{i.log.debug("initializing vad");let r=await t(),n=await e.InferenceSession.create(r),a=new e.Tensor("int64",[16000n]),s=Array(128).fill(0),l=new e.Tensor("float32",s,[2,1,64]),h=new e.Tensor("float32",s,[2,1,64]);return i.log.debug("vad is initialized"),new o(e,n,l,h,a)}},7674:(e,t,r)=>{Object.defineProperty(t,"__esModule",{value:!0}),t.PlatformAgnosticNonRealTimeVAD=t.defaultNonRealTimeVADOptions=void 0;let i=r(6472),o=r(3544),n=r(4117),a=r(7279);t.defaultNonRealTimeVADOptions={...i.defaultLegacyFrameProcessorOptions,ortConfig:void 0};class s{static async _new(e,r,i={}){let o={...t.defaultNonRealTimeVADOptions,...i};void 0!==o.ortConfig&&o.ortConfig(r);let n=new this(e,r,o);return await n.init(),n}constructor(e,t,r){this.modelFetcher=e,this.ort=t,this.options=r,this.init=async()=>{let e=await n.SileroLegacy.new(this.ort,this.modelFetcher);this.frameProcessor=new i.FrameProcessor(e.process,e.reset_state,{frameSamples:this.options.frameSamples,positiveSpeechThreshold:this.options.positiveSpeechThreshold,negativeSpeechThreshold:this.options.negativeSpeechThreshold,redemptionFrames:this.options.redemptionFrames,preSpeechPadFrames:this.options.preSpeechPadFrames,minSpeechFrames:this.options.minSpeechFrames,submitUserSpeechOnPause:this.options.submitUserSpeechOnPause}),this.frameProcessor.resume()},this.run=async function*(e,t){let r={nativeSampleRate:t,targetSampleRate:16e3,targetFrameSize:this.options.frameSamples},i=new a.Resampler(r),n=0,s=0,l=0;for await(let t of i.stream(e)){let{msg:e,audio:r}=await this.frameProcessor.process(t);switch(e){case o.Message.SpeechStart:n=l*this.options.frameSamples/16;break;case o.Message.SpeechEnd:s=(l+1)*this.options.frameSamples/16,yield{audio:r,start:n,end:s}}l++}let{msg:h,audio:d}=this.frameProcessor.endSegment();h==o.Message.SpeechEnd&&(yield{audio:d,start:n,end:l*this.options.frameSamples/16})},(0,i.validateOptions)(r)}}t.PlatformAgnosticNonRealTimeVAD=s},9766:(e,t)=>{Object.defineProperty(t,"__esModule",{value:!0})}}]);